#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'pp'

require './lib/helper'
require './lib/newick'
require './lib/multi_io'
require './lib/numeric'
require './lib/array'
require './lib/hash'


class OptimalSolution < Thor
  desc "generate", "generate optimal solution for load balancing with subtree repeats for one tree"
  option :tree_file, :required => true, :aliases => "-t",
         :desc => "Which tree should be load balanced. " \
                  "Example: '-t ./data/59/parsimony_trees/RAxML_result.T4.RUN.0' "
  option :partition_file, :required => true, :aliases => "-p",
         :desc => "Path to partition file " \
                  "Example: '-p ./data/7/7.partitions' "
  option :phylip_file, :required => true, :aliases => "-l",
         :desc => "Path to phylip file " \
                  "Example: '-l ./data/7/7.phy' "
  option :number_of_bins, :type => :numeric, :default => 2, :aliases => "-b",
         :desc => "Number of bins that the sites should be distributed to. " \
                  "Example: '-b 3' "
  option :crop_partitions, :type => :numeric, :default => 2, :aliases => "-n",
         :desc => "Crop the datafile to x partitions. " \
                  "Example: '-n 3' "
  option :crop_sites_per_partition, :type => :numeric, :default => 8, :aliases => "-s",
         :desc => "Crop the number of sites in each partition to x. Recommended maximum bins to total sites: 2-20 | 3-14 | 4-12" \
                  "Example: '-s 7' "
  option :number_of_processes, :type => :numeric, :default => 3, :aliases => "-P",
         :desc => "Parallel processing on 'x' cores. If 0 multithreading is disabled. " \
                  "Example: '-P 2' "

  def generate

    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    sample_root = 'midpoint'
    start_time = Time.now
    partitions = read_partitions(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join("-")} #{start_time.strftime "%Y-%m-%d %H-%M-%S"}"

    # Drop identical sites
    unless partition_file.include?("uniq")
      number_of_sites, partitions, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Program started at #{start_time}"
    puts "Using parameters: Tree file: #{options[:tree_file]}; " \
         "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
         "Sample root nodes: #{sample_root}; " \
         "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
         "Number of partitions: #{partitions.size}"



    # Crop partitions and list all sites
    partitions_limiter = 0
    list_of_sites = partitions.map do |partition_name, partition_range|
      partitions_limiter += 1
      next if partitions_limiter > options[:crop_partitions]
      (partition_range.begin .. partition_range.begin + options[:crop_sites_per_partition] - 1).map {|i| {i => partition_name} }
    end.flatten.compact

    # Distribute to bins
    puts "Calculating number of distributions for #{options[:crop_sites_per_partition]} sites for #{options[:crop_partitions]} partitions over #{options[:number_of_bins]} bin"
    distributions = list_of_sites.distribute_to_bins(options[:number_of_bins]).to_a
    puts "Result: #{distributions.size} distributions"

    # Get data
    tree = NewickTree.fromFile(options[:tree_file])
    tree = tree.add_dna_sequences(phylip_data)

    # Midpoint root
    tree = tree.set_edge_length.midpoint_root

    # Test each distribution and save best distribution
    results = Parallel.map_with_index(distributions, :in_processes => options[:number_of_processes]) do |distribution, index|
      dist_operations_maximum = 0
      dist_operations_optimized = 0

      distribution.each do |bin|
        bin_operations_maximum = 0
        bin_operations_optimized = 0

        # Generate partition distribution
        partitions = Hash.new([])
        bin.each { |site| partitions[site.values[0]] = partitions[site.values[0]] + [site.keys[0]]}

        # Iterate over all partitions
        partitions.each do |partition_name, partition_range|
          result = tree.ml_operations(partition_range)
          bin_operations_maximum += result[0]
          bin_operations_optimized += result[1]
        end

        # Get the operations count for the largest bin -> bottleneck
        if bin_operations_optimized > dist_operations_optimized
          dist_operations_optimized = bin_operations_optimized
          dist_operations_maximum = bin_operations_maximum
        end

      end

      # Progress indicator
      print "." if index % (distributions.size / 100) == 0

      [dist_operations_optimized, dist_operations_maximum, distribution]
    end

    minimum = results.min_by(&:first)

    savings_in_largest_bin = ((minimum[1] - minimum[0]).to_f/minimum[1].to_f*100).round(2)
    puts "Absolute minimum #{minimum[0]} with savings of #{savings_in_largest_bin} in largest bin. Distribution"
    pp minimum[2]

    csv_output = []
    minimum[2].each_with_index do |bin, bin_index|
      bin.each_with_index do |element|
        csv_output << {element: element.keys[0], bin: bin_index, partition: element.values[0]}
      end
    end

    program_runtime = (Time.now - start_time).duration

    # Check if output folder exists
    output_directory = "./output_#{File.basename(__FILE__, ".rb")}"
    FileUtils.mkdir_p(output_directory)

    # Output results to CSV for R
    data_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} data.csv"
    puts "Writing data to #{data_file}"
    csv_output.flatten.array_of_hashes_to_csv_file(data_file)


    # Output parameters to CSV for R
    program_parameters_output = { phylip_file: phylip_file, sample_root: sample_root,
                                  options[:number_of_bins] => options[:number_of_bins],
                                  options[:crop_partitions] => options[:crop_partitions],
                                  options[:crop_sites_per_partition] => options[:crop_sites_per_partition],
                                  options[:number_of_processes] => options[:number_of_processes],
                                  savings_in_largest_bin: savings_in_largest_bin, operations_optimized: minimum[0],
                                  program_runtime: program_runtime, data_file: data_file,
                                  graph_file_name: graph_file_name}

    parameter_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} parameters.csv"
    program_parameters_output.to_csv_file(parameter_file)
    puts "Program parameters written to #{parameter_file}"
    puts "Run corresponding R script '#{File.basename(__FILE__, ".rb")}.R' to generate graphs"

    puts "Program finished at #{Time.now}. Runtime: #{program_runtime}"

  end

end

OptimalSolution.start

#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'fileutils'
require 'pp'
require 'ruby-progressbar'

require './lib/helper'
require './lib/newick'
require './lib/multi_io'
require './lib/numeric'
require './lib/array'
require './lib/hash'
require './lib/partition_array'


class OptimalSolution < Thor
  desc "generate", "generate optimal solution for load balancing with subtree repeats for one tree"
  option :tree_file, :required => true, :aliases => "-t",
         :desc => "Which tree should be load balanced. " \
                  "Example: '-t ./data/59/parsimony_trees/RAxML_result.T4.RUN.0' "
  option :partition_file, :required => true, :aliases => "-p",
         :desc => "Path to partition file " \
                  "Example: '-p ./data/7/7.partitions' "
  option :phylip_file, :required => true, :aliases => "-l",
         :desc => "Path to phylip file " \
                  "Example: '-l ./data/7/7.phy' "
  option :number_of_bins, :type => :numeric, :default => 2, :aliases => "-b",
         :desc => "Number of bins that the sites should be distributed to. " \
                  "Example: '-b 3' "
  option :crop_partitions, :type => :numeric, :default => 2, :aliases => "-n",
         :desc => "Crop the datafile to x partitions. " \
                  "Example: '-n 3' "
  option :crop_sites_per_partition, :type => :numeric, :default => 5, :aliases => "-s",
         :desc => "Crop the number of sites in each partition to x. Recommended maximum bins to total sites: 2-20 | 3-14 | 4-12 " \
                  "Example: '-s 7' "
  option :number_of_processes, :type => :numeric, :default => 3, :aliases => "-P",
         :desc => "Parallel processing on 'x' cores. If 0 multithreading is disabled. " \
                  "Example: '-P 2' "

  def generate

    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    sample_root = 'midpoint'
    start_time = Time.now
    partitions = PartitionArray.from_file(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join("-")} #{start_time.strftime "%Y-%m-%d %H-%M-%S"}"

    # Drop identical sites
    unless partition_file.include?("uniq")
      number_of_sites, partitions, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Program started at #{start_time}"
    puts "Using parameters: Tree file: #{options[:tree_file]}; " \
         "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
         "Sample root nodes: #{sample_root}; " \
         "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
         "Number of partitions: #{partitions.size}"



    # Crop partitions and list all sites
    partitions_limiter = 0
    list_of_sites = partitions.map do |partition|
      partitions_limiter += 1
      next if partitions_limiter > options[:crop_partitions]
      (partition.sites.first ... partition.sites.first + options[:crop_sites_per_partition]).map {|i| {i => partition.name} }
    end.flatten.compact

    # Distribute to bins
    puts "Calculating number of distributions for #{options[:crop_sites_per_partition]} sites for #{options[:crop_partitions]} partitions over #{options[:number_of_bins]} bins"
    distributions = list_of_sites.distribute_to_bins(options[:number_of_bins]).to_a
    puts "Result: #{distributions.size} distributions"

    # Get data
    tree = NewickTree.fromFile(options[:tree_file])
    tree = tree.add_dna_sequences(phylip_data)

    # Midpoint root
    tree = tree.set_edge_length.midpoint_root

    # Test each distribution and save best distribution
    results = Parallel.map(distributions, :in_processes => options[:number_of_processes], :progress => "Checking all distributions") do |distribution|
      dist_operations_maximum = 0
      dist_operations_optimized = 0

      # Iterate over each bin of the current distribution
      distribution.each_index do |bin_index|
        bin_operations_maximum = 0
        bin_operations_optimized = 0

        # Convert sites array to partitions array for current bin
        distribution[bin_index] = distribution[bin_index].each_with_object(Hash.new([])) { |site, partitions| partitions[site.values[0]] = partitions[site.values[0]] + [site.keys[0]]}

        # Iterate over all partitions and add up operations for this bin
        distribution[bin_index].each do |partition_name, partition_range|
          result = tree.ml_operations(partition_range)
          bin_operations_maximum += result[:op_maximum]
          bin_operations_optimized += result[:op_optimized]
        end

        # Get the operations count for the largest bin of the current distribution -> bottleneck
        if bin_operations_optimized > dist_operations_optimized
          dist_operations_optimized = bin_operations_optimized
          dist_operations_maximum = bin_operations_maximum
        end

      end

      [dist_operations_optimized, dist_operations_maximum, distribution]
    end

    minimum = results.min_by(&:first)

    savings_in_largest_bin = ((minimum[1] - minimum[0]).to_f/minimum[1].to_f*100).round(2)
    puts "Absolute minimum #{minimum[0]} with savings of #{savings_in_largest_bin} in largest bin. \nDistribution:"
    pp minimum[2]

    # CSV output for best solution
    csv_output = []
    minimum[2].each_with_index do |bin, bin_index|
      # Iterate over all partitions and add up operations for this bin
      bin.each do |partition_name, partition_sites|
        tree.clear_calculated_subtrees
        # Iterate over each site in the partition since we want operations per site in the output
        partition_sites.each do |site|
          csv_output << {solution: "best", bin: bin_index,
                         site: site, partition: partition_name,
                         operations: tree.ml_operations([site], false)[:op_optimized]}
        end
      end
    end

    # Generate simple solution #
    # How many sites go into each bin for an even distribution
    simple_solution = (0 ... options[:number_of_bins]).to_a.map do |bin|
      if (bin * options[:number_of_bins] / options[:number_of_bins]) < (list_of_sites.size % options[:number_of_bins])
        list_of_sites.size / options[:number_of_bins] + 1
      else
        list_of_sites.size / options[:number_of_bins]
      end
    end
    # Distribute sites accordingly
    simple_solution.map! do |bin|
      sites = list_of_sites.slice!((0..bin - 1))
      sites.each_with_object(Hash.new([])) { |site, partitions| partitions[site.values[0]] = partitions[site.values[0]] + [site.keys[0]]}
    end

    # CSV output for simple solution
    simple_solution.each_with_index do |bin, bin_index|
      bin.each do |partition_name, partition_sites|
        tree.clear_calculated_subtrees
        # Iterate over each site in the partition since we want operations per site in the output
        partition_sites.each do |site|
          csv_output << {solution: "simple", bin: bin_index,
                         site: site, partition: partition_name,
                         operations: tree.ml_operations([site], false)[:op_optimized]}
        end
      end
    end

    program_runtime = (Time.now - start_time).duration

    # Check if output folder exists
    output_directory = "./output_#{File.basename(__FILE__, ".rb")}"
    FileUtils.mkdir_p(output_directory)

    # Output results to CSV for R
    data_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} data.csv"
    puts "Writing data to #{data_file}"
    csv_output.flatten.array_of_hashes_to_csv_file(data_file)


    # Output parameters to CSV for R
    program_parameters_output = { phylip_file: phylip_file, sample_root: sample_root,
                                  number_of_bins: options[:number_of_bins],
                                  crop_partitions: options[:crop_partitions],
                                  crop_sites_per_partition: options[:crop_sites_per_partition],
                                  number_of_processes: options[:number_of_processes],
                                  savings_in_largest_bin: savings_in_largest_bin, operations_optimized: minimum[0],
                                  program_runtime: program_runtime, data_file: data_file,
                                  graph_file_name: graph_file_name}

    parameter_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} parameters.csv"
    program_parameters_output.to_csv_file(parameter_file)
    puts "Program parameters written to #{parameter_file}"
    puts "Run corresponding R script '#{File.basename(__FILE__, ".rb")}.R' to generate graphs"

    puts "Program finished at #{Time.now}. Runtime: #{program_runtime}"

  end

end

OptimalSolution.start

#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'fileutils'
require 'pp'
require 'ruby-progressbar'
#require 'Newick' # Some problem with including the forked gem
require 'require_all'
require 'deep_clone'
#require 'stackprof' # Used for profiling
require 'matrix'

require_all 'lib'


class Scheduling < Thor
  desc 'generate', 'schedule partitions on bins considering subtree repeats for one tree'
  option :tree_file, :required => true, :aliases => '-t',
         :desc => 'Which tree should be used ' \
                  "Example: '-t ./data/59/parsimony_trees/RAxML_result.T4.RUN.0' "
  option :partition_file, :required => true, :aliases => '-p',
         :desc => 'Path to partition file ' \
                  "Example: '-p ./data/59/59.partitions' "
  option :phylip_file, :required => true, :aliases => '-l',
         :desc => 'Path to phylip file ' \
                  "Example: '-l ./data/59/59.phy' "
  option :number_of_bins, :type => :numeric, :required => true, :aliases => '-b',
         :desc => 'Number of bins that the sites should be distributed to. ' \
                  "Example: '-b 3' "
  option :groundtruth, :type => :boolean, :default => false, :aliases => '-g',
         :desc => 'Compare the heuristics with the groundtruth. ' \
                  'If true the dataset will be cropped since the groundtruth can only handle a limited amount of sites. ' \
                  "Example: '-g true' "
  option :crop_partitions, :type => :numeric, :default => 2, :aliases => "-n",
         :desc => "Crop the datafile to x partitions. " \
                  "Example: '-n 3' "
  option :crop_sites_per_partition, :type => :numeric, :default => 5, :aliases => "-s",
         :desc => "Crop the number of sites in each partition to x. Recommended maximum bins to total sites: 2-20 | 3-14 | 4-12 " \
                  "Example: '-s 7' "

  def generate

    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    sample_root = 'midpoint'
    # heuristic_options = ['odda', 'cut', 'grdy', 'grdy2', 'grdy3', 'slice']
    heuristic_options = ['odda', 'cut', 'grdy']
    optimization_options = ['low-src', 'red-max']
    csv_output = []
    start_time = Time.now
    partitions_master = PartitionArray.from_file(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join('-')} #{start_time.strftime '%Y-%m-%d %H-%M-%S'}"

    puts "Program started at #{start_time}"

    # Drop identical sites
    unless partition_file.include?('uniq')
      number_of_sites, partitions_master, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions_master, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Using parameters: tree_file: #{options[:tree_file]}; " \
         "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
         "Sample root nodes: #{sample_root}; " \
         "Number of bins: #{options[:number_of_bins]}; " \
         "Groundtruth: #{options[:groundtruth]}; " \
         "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
         "Number of partitions: #{partitions_master.size}"

    # Crop partitions if we calculate the groundtruth
    if options[:groundtruth]
      heuristic_options << 'grdtruth'
      partitions_master.crop!(options[:crop_partitions], options[:crop_sites_per_partition])
    end

    # Get data
    puts 'Getting data'
    tree_master = NewickTree.fromFile(options[:tree_file])
    tree_master = tree_master.add_dna_sequences(phylip_data)

    # Midpoint root
    tree_master.set_edge_length!.midpointRoot

    # Get partition sizes and sort by operations
    partitions_master.add_tree!(tree_master).sort!

    # Initialize bin list
    bins_master = BinArray.new(options[:number_of_bins])

    # Set lower bound for heuristics
    bins_master.set_lower_bound!(partitions_master)
    bins_master.set_operations_worst_case!(partitions_master)



    # Iterate over all heuristics with standard sorting of sites
    heuristic_options.each do |heuristic|
      csv_output << apply_heuristic(heuristic, optimization_options, bins_master, partitions_master, tree_master)
    end


    # Lexicographic sorting of sites
    puts 'Sorting sites lexicographically'
    tree_master.lexi_sort!(partitions_master)
    partitions_master.add_tree!(tree_master, false)
    # Don't apply 'groundtruth' for lexicographic sorted MSA
    heuristic_options.delete('grdtruth')


    heuristic_options.each do |heuristic|
      csv_output << apply_heuristic("#{heuristic}_lxi", optimization_options, bins_master, partitions_master, tree_master)
    end


    program_runtime = (Time.now - start_time).duration

    # Check if output folder exists
    output_directory = "./output_#{File.basename(__FILE__, '.rb')}"
    FileUtils.mkdir_p(output_directory)

    # Output results to CSV for R
    data_file = "#{output_directory}/#{start_time.strftime '%Y-%m-%d %H-%M-%S'} data.csv"
    puts "Writing data to #{data_file}"
    csv_output.flatten.array_of_hashes_to_csv_file(data_file)


    # Output parameters to CSV for R
    program_parameters_output = { number_of_bins: options[:number_of_bins], groundtruth: options[:groundtruth],
                                  phylip_file: phylip_file, sample_root: sample_root,
                                  program_runtime: program_runtime, data_file: data_file,
                                  graph_file_name: graph_file_name
    }

    parameter_file = "#{output_directory}/#{start_time.strftime '%Y-%m-%d %H-%M-%S'} parameters.csv"
    program_parameters_output.to_csv_file(parameter_file)
    puts "Program parameters written to #{parameter_file}"
    puts "Run corresponding R script '#{File.basename(__FILE__, '.rb')}.R' to generate graphs"

    puts "Program finished at #{Time.now}. Runtime: #{program_runtime}"


  end

end

Scheduling.start

#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'fileutils'
require 'pp'
require 'ruby-progressbar'

require './lib/helper'
require './lib/newick'
require './lib/multi_io'
require './lib/numeric'
require './lib/array'
require './lib/hash'
require './lib/bin_array'
require './lib/partition_array'


class Scheduling < Thor
  desc "generate", "schedule partitions on bins considering subtree repeats for one tree"
  option :tree_file, :required => true, :aliases => "-t",
         :desc => "Which tree should be used " \
                  "Example: '-t ./data/59/parsimony_trees/RAxML_result.T4.RUN.0' "
  option :partition_file, :required => true, :aliases => "-p",
         :desc => "Path to partition file " \
                  "Example: '-p ./data/59/59.partitions' "
  option :phylip_file, :required => true, :aliases => "-l",
         :desc => "Path to phylip file " \
                  "Example: '-l ./data/59/59.phy' "
  option :number_of_bins, :type => :numeric, :default => 3, :aliases => "-n",
         :desc => "Number of bins that the sites should be distributed to. " \
                  "Example: '-n 3' "
  option :number_of_processes, :type => :numeric, :default => 3, :aliases => "-P",
         :desc => "Parallel processing on 'x' cores. If 0 multithreading is disabled. " \
                  "Example: '-P 2' "

  def generate

    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    sample_root = 'midpoint'
    start_time = Time.now
    partitions = PartitionArray.from_file(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join("-")} #{start_time.strftime "%Y-%m-%d %H-%M-%S"}"

    # Drop identical sites
    unless partition_file.include?("uniq")
      number_of_sites, partitions, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Program started at #{start_time}"
    puts "Using parameters: Tree file: #{options[:tree_file]}; " \
         "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
         "Sample root nodes: #{sample_root}; " \
         "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
         "Number of partitions: #{partitions.size}"


    # Get data
    tree = NewickTree.fromFile(options[:tree_file])
    tree = tree.add_dna_sequences(phylip_data)

    # Midpoint root
    tree = tree.set_edge_length.midpoint_root

    # Get partition sizes
    partitions.ml_operations(tree)

    # Initialize bin list
    bins = BinArray.new(options[:number_of_bins])

    # Set bin target size for sliding window heuristic
    bins.set_bin_target_size(partitions.op_optimized_size)

    # Sort partitions by op_optimized
    partitions = partitions.sort

    # Initial fill: Fill sorted partitions into bins as far as possible without breaking
    remaining_partitions = bins.initial_fill(partitions)
    puts remaining_partitions
    puts bins


    ####################
    ## Sliding Window ##
    ####################

    # Calculate ratio of free space
    free_space = bins.map {|bin| bin_max_size - bin.map {|key, value| value[:operations]}.reduce(:+)}
    total_free_space = free_space.reduce(:+)
    ratio = free_space.map {|bin_space| bin_space.to_f/total_free_space}

    # Total sites that need to be distributed
    total_sites = remaining_partitions.map {|partition| partition[1][:partition_range].size}.reduce(:+)

    # Fill each bin
    bins.size.times do
      # How many sites need to go into the current bin
      sites_for_bin = (ratio[bin_assigner] * total_sites).ceil # FIXME: It's probably better to round down and save overflow in last bin

      until remaining_partitions.empty? do
        # partition fits entirely in open space of bin -> move to next bin afterwards
        if remaining_partitions[0][1][:partition_range].size == sites_for_bin
          bins[bin_assigner].merge!({remaining_partitions[0][0] => remaining_partitions[0][1]})
          remaining_partitions = remaining_partitions.drop(1)
          break
        # partition is bigger than space available -> crop partition + move to next bin afterwards
        elsif remaining_partitions[0][1][:partition_range].size > sites_for_bin
          bins[bin_assigner].merge!({remaining_partitions[0][0] =>
                                      {partition_range: (remaining_partitions[0][1][:partition_range].begin .. remaining_partitions[0][1][:partition_range].begin + sites_for_bin - 1),
                                       operations: remaining_partitions[0][1][:operations]}})

          # Crop partition
          remaining_partitions[0][1][:partition_range] =
              (remaining_partitions[0][1][:partition_range].begin + sites_for_bin .. remaining_partitions[0][1][:partition_range].end)
          break
        # partition is smaller than open space -> stay in current bin + reduce available space + drop partition
        else
          bins[bin_assigner].merge!({remaining_partitions[0][0] => remaining_partitions[0][1]})
          sites_for_bin -= remaining_partitions[0][1][:partition_range].size
          remaining_partitions = remaining_partitions.drop(1)
        end
      end

      bin_assigner = (bin_assigner + 1) % bins.size
    end

    puts bins.map {|bin| bin.map {|key, value| value[:operations]}.reduce(:+)}

    ## Optimization
    sequence = bins.size.times.to_a.rotate(bin_assigner)
    sequence.pop

    10.times do
      average_bin_size = bins.map {|bin| bin.map {|key, value| value[:operations]}.reduce(:+)}.reduce(:+)/bins.size
      sequence.each do |bin_index|
        bin_size = bins[bin_index].map {|key, value| value[:operations]}.reduce(:+)
        if bin_size < average_bin_size
          # Get from following bin
          bins[(bin_index + 1) % bins.size].
              elsif bin_size > average_bin_size
          # Give following bin
          bins[(bin_index + 1) % bins.size]
        end
      end
    end





  end

end

Scheduling.start

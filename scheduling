#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'fileutils'
require 'pp'
require 'ruby-progressbar'
require 'Newick'
require 'require_all'

require_all 'lib'


class Scheduling < Thor
  desc "generate", "schedule partitions on bins considering subtree repeats for one tree"
  option :tree_file, :required => true, :aliases => "-t",
         :desc => "Which tree should be used " \
                  "Example: '-t ./data/59/parsimony_trees/RAxML_result.T4.RUN.0' "
  option :partition_file, :required => true, :aliases => "-p",
         :desc => "Path to partition file " \
                  "Example: '-p ./data/59/59.partitions' "
  option :phylip_file, :required => true, :aliases => "-l",
         :desc => "Path to phylip file " \
                  "Example: '-l ./data/59/59.phy' "
  option :number_of_bins, :type => :numeric, :default => 3, :aliases => "-n",
         :desc => "Number of bins that the sites should be distributed to. " \
                  "Example: '-n 3' "
  option :number_of_processes, :type => :numeric, :default => 0, :aliases => "-P",
         :desc => "Parallel processing on 'x' cores. If 0 multithreading is disabled. [Not implemented]" \
                  "Example: '-P 2' "

  def generate

    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    sample_root = 'midpoint'
    heuristic_options = ["greedy", "slice"]
    optimization_options = []
    #optimization_options = ["min_max_shift", "reduce_max", "bad_sites"]
    csv_output = []
    start_time = Time.now
    partitions_master = PartitionArray.from_file(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join("-")} #{start_time.strftime "%Y-%m-%d %H-%M-%S"}"

    # Drop identical sites
    unless partition_file.include?("uniq")
      number_of_sites, partitions_master, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions_master, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Program started at #{start_time}"
    puts "Using parameters: tree_file: #{options[:tree_file]}; " \
         "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
         "Sample root nodes: #{sample_root}; " \
         "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
         "Number of partitions: #{partitions_master.size}"


    # Get data
    tree_master = NewickTree.fromFile(options[:tree_file])
    tree_master = tree_master.add_dna_sequences(phylip_data)

    # Midpoint root
    tree_master.set_edge_length!.midpointRoot

    # Get partition sizes and sort by operations
    partitions_master.add_tree!(tree_master).sort!

    # Initialize bin list
    bins_master = BinArray.new(options[:number_of_bins])

    # Set lower bound for heuristics
    bins_master.set_lower_bound!(partitions_master)


    ## Original scheduling as reference ##
    # Get clean data
    bins, partitions, tree =
        deep_clone(bins_master, partitions_master, tree_master)

    bins.original_scheduling!(partitions)
    csv_output << bins.to_csv("original_scheduling")


    # Standard sorting of sites
    heuristic_options.each do |heuristic|
      # Get clean data
      bins, partitions, tree =
          deep_clone(bins_master, partitions_master, tree_master)

      # Initial fill: Fill sorted partitions into bins as far as possible without breaking the partitions
      remaining_partitions = bins.initial_fill!(partitions)

      bins.apply_heuristic!(heuristic, remaining_partitions)
      csv_output << bins.to_csv(heuristic)

      optimization_options.each do |optimization|
        bins.optimize!(optimization)
        csv_output << bins.to_csv("#{heuristic}_#{optimization}")
      end
    end


    # Lexicographic sorting of sites
    tree_master.sort_sites!(partitions_master) # TODO: Check whether this actually works

    heuristic_options.each do |heuristic|
      # Get clean data
      bins, partitions, tree =
          deep_clone(bins_master, partitions_master, tree_master)

      # Initial fill: Fill sorted partitions into bins as far as possible without breaking the partitions
      remaining_partitions = bins.initial_fill!(partitions)

      bins.apply_heuristic!(heuristic, remaining_partitions)
      csv_output << bins.to_csv("#{heuristic}_lexi")

      optimization_options.each do |optimization|
        bins.optimize!(optimization)
        csv_output << bins.to_csv("#{heuristic}_lexi_#{optimization}")
      end
    end


    program_runtime = (Time.now - start_time).duration

    # Check if output folder exists
    output_directory = "./output_#{File.basename(__FILE__, ".rb")}"
    FileUtils.mkdir_p(output_directory)

    # Output results to CSV for R
    data_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} data.csv"
    puts "Writing data to #{data_file}"
    csv_output.flatten.array_of_hashes_to_csv_file(data_file)


    # Output parameters to CSV for R
    program_parameters_output = { number_of_bins: options[:number_of_bins], optimize_result: options[:optimize],
                                  phylip_file: phylip_file, sample_root: sample_root,
                                  number_of_processes: options[:number_of_processes],
                                  program_runtime: program_runtime, data_file: data_file,
                                  graph_file_name: graph_file_name,
    }

    parameter_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} parameters.csv"
    program_parameters_output.to_csv_file(parameter_file)
    puts "Program parameters written to #{parameter_file}"
    puts "Run corresponding R script '#{File.basename(__FILE__, ".rb")}.R' to generate graphs"

    puts "Program finished at #{Time.now}. Runtime: #{program_runtime}"


  end



end

Scheduling.start

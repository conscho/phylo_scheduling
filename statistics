#!/usr/bin/env ruby

require 'rubygems'
require 'thor'
require 'parallel'
require 'fileutils'

require './lib/helper'
require './lib/newick'
require './lib/multi_io'
require './lib/numeric'
require './lib/array'
require './lib/hash'


# Command line tool via rubygem Thor
class Statistics < Thor
  desc "generate", "generate statistics for RAxML output"
  option :batches, :type => :hash, :required => true, :aliases => "-b",
         :desc => "Which batches of trees you want to compare. " \
                  "Example: '-b pars:./data/7/parsimony_trees/*parsimonyTree* rand_ml:./data/7/random_trees/*result*' "
  option :partition_file, :required => true, :aliases => "-p",
         :desc => "Path to partition file " \
                  "Example: '-p ./data/7/7.partitions' "
  option :phylip_file, :required => true, :aliases => "-l",
         :desc => "Path to phylip file " \
                  "Example: '-l ./data/7/7.phy' "
  option :sample_root, :default => "midpoint", :aliases => "-r",
         :desc => "Enter the amount of nodes (>= 2) that should be used to root the tree. Enter 'all' for all nodes. Enter 'midpoint' for midpoint root. " \
                  "Example: '-r all' "
  option :sample_trees, :default => "all", :aliases => "-t",
         :desc => "Enter the amount of trees that should be used for statistics. Enter 'all' for all trees. " \
                  "Example: '-t 12' "
  option :compare_with_likelihood, :type => :boolean, :default => true, :aliases => "-l",
         :desc => "Create plot with ratio of savings to likelihood distribution. Only works with RAxML naming of files. " \
                  "Example: '-l false' "
  option :number_of_processes, :type => :numeric, :default => 0, :aliases => "-P",
         :desc => "Parallel processing on 'x' cores. If 0 multithreading is disabled. " \
                  "Example: '-P 4' "
  option :split_partitions, :type => :boolean, :default => false, :aliases => "-s",
         :desc => "Split each partition in the middle to get an example of savings loss due to splitting partitions. " \
                  "Example: '-s true' "

  def generate
    
    # Initialize
    partition_file = options[:partition_file]
    phylip_file = options[:phylip_file]
    start_time = Time.now
    csv_output = []
    partitions = read_partitions(partition_file)
    number_of_taxa, number_of_sites, phylip_data = read_phylip(phylip_file)
    graph_file_name = "graphs/#{phylip_file.scan(/(\w+)\//).join("-")} #{start_time.strftime "%Y-%m-%d %H-%M-%S"}"

    # Drop identical sites
    unless partition_file.include?("uniq")
      number_of_sites, partitions, phylip_data, partition_file, phylip_file =
          drop_unique_sites(partitions, phylip_data, partition_file, phylip_file, number_of_taxa)
    end

    puts "Program started at #{start_time}"
    puts "Using parameters: Tree files: #{options[:batches]}; " \
     "Partition file: #{partition_file}; Phylip File: #{phylip_file}; " \
     "Sample root nodes: #{options[:sample_root]}; Sample trees: #{options[:sample_trees]}; " \
     "Number of taxa: #{number_of_taxa}; Number of sites: #{number_of_sites}; " \
     "Number of partitions: #{partitions.size}; Number of processes: #{options[:number_of_processes]}"


    # Get likelihood values also?
    likelihoods = read_likelihood(options[:batches]) if options[:compare_with_likelihood]

    options[:batches].each do |batch_name, batch_path|

      # Shall we sample the trees
      list_of_trees = if options[:sample_trees] == "all"
                        Dir.glob(batch_path)
                      else
                        Dir.glob(batch_path).first(options[:sample_trees].to_i)
                      end

      csv_output << Parallel.map(list_of_trees, :in_processes => options[:number_of_processes]) do |file|

        # Initialize
        tree_output = []

        # Get data
        puts "Processing file: #{file}"
        tree = NewickTree.fromFile(file)
        tree = tree.add_dna_sequences(phylip_data)

        # Get likelihood for current tree
        if options[:compare_with_likelihood]
          match_object = /.*\.(?<prefix>.*)\.RUN\.(?<tree_number>.*)/.match(file)
          likelihood = likelihoods[batch_name + '-' + match_object[:prefix] + '-' + match_object[:tree_number]]
        else
          likelihood = 0
        end

        # Sample root, midpoint root or root once on all nodes?
        root_nodes = []
        if options[:sample_root] == "all"
          root_nodes = tree.nodes
        elsif options[:sample_root] == "midpoint"
          tree = tree.set_edge_length.midpoint_root
          root_nodes[0] = tree.root
        else
          root_nodes = tree.nodes.first(options[:sample_root])
        end

        root_nodes.each_with_index do |node, root_index|

          # Root tree unless the parameter midpoint root (root_nodes.size == 1) has been chosen
          tree.reroot(node) unless root_nodes.size == 1
          height = tree.height

          # Iterate over all partitions
          partitions.each do |partition_name, partition_range|

            # Split partitions to get a feeling for the efficiency loss
            if options[:split_partitions]

              # Split in the middle of each partition
              split_at = partition_range.size / 2

              result_until_split = tree.ml_operations(partition_range.begin .. (partition_range.begin + split_at))
              result_after_split = tree.ml_operations((partition_range.begin + split_at + 1) .. partition_range.end)

              tree_output << { batch: batch_name, tree: file, likelihood: likelihood,
                               root_node: root_index.to_s, height: height, partition: partition_name.to_s,
                               operations_maximum: result_until_split[0] + result_after_split[0],
                               operations_optimized: result_until_split[1] + result_after_split[1],
                               ratio_of_savings: (((result_until_split[0] + result_after_split[0]) -
                                   (result_until_split[1] + result_after_split[1])).to_f /
                                   (result_until_split[0] + result_after_split[0]).to_f * 100),
                               options[:split_partitions] => 1 }

            end

            result = tree.ml_operations(partition_range)

            tree_output << { batch: batch_name, tree: file, likelihood: likelihood,
                             root_node: root_index.to_s, height: height, partition: partition_name.to_s,
                             operations_maximum: result[0], operations_optimized: result[1],
                             ratio_of_savings: result[2], options[:split_partitions] => 0 }

          end

          # Simple progress indicator
          print "." if root_index % (root_nodes.size / 100) == 0 if root_nodes.size > 100

        end

        tree_output

      end

    end


    program_runtime = (Time.now - start_time).duration

    # Check if output folder exists
    output_directory = "./output_#{File.basename(__FILE__, ".rb")}"
    FileUtils.mkdir_p(output_directory)

    # Output results to CSV for R
    data_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} data.csv"
    puts "Writing data to #{data_file}"
    csv_output.flatten.array_of_hashes_to_csv_file(data_file)


    # Output parameters to CSV for R
    program_parameters_output = { phylip_file: phylip_file,
                                  options[:sample_root] => options[:sample_root],
                                  options[:sample_trees] => options[:sample_trees],
                                  options[:compare_with_likelihood] => options[:compare_with_likelihood],
                                  options[:number_of_processes] => options[:number_of_processes],
                                  options[:split_partitions] => options[:split_partitions],
                                  number_of_partitions: partitions.size,
                                  number_of_taxa: number_of_taxa, number_of_sites: number_of_sites,
                                  program_runtime: program_runtime, data_file: data_file,
                                  graph_file_name: graph_file_name }


    parameter_file = "#{output_directory}/#{start_time.strftime "%Y-%m-%d %H-%M-%S"} parameters.csv"
    program_parameters_output.to_csv_file(parameter_file)
    puts "Program parameters written to #{parameter_file}"
    puts "Run corresponding R script '#{File.basename(__FILE__, ".rb")}.R' to generate graphs"

    puts "Program finished at #{Time.now}. Runtime: #{program_runtime}"

  end


end

Statistics.start